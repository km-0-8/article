# ã€pythonã€‘çµ±è¨ˆå­¦ã‹ã‚‰ç´è§£ãæ©Ÿæ¢°å­¦ç¿’-â‘¥ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°-

æœ¬ã‚·ãƒªãƒ¼ã‚ºã§ã¯ã€çµ±è¨ˆå­¦ã®è¦–ç‚¹ã‹ã‚‰æ©Ÿæ¢°å­¦ç¿’ã‚’ç´è§£ãã“ã¨ã‚’ä¸»çœ¼ã«ã€åŸºç¤çš„ãªç†è«–ã¨Pythonã‚’ç”¨ã„ãŸå®Ÿè£…ä¾‹ã‚’äº¤ãˆã¦ã€å®Ÿè·µçš„ã«è§£èª¬ã—ã¦ã„ãã¾ã™ã€‚
ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä»•çµ„ã¿ã‚„æ•°å¼ã®èƒŒæ™¯ã ã‘ã§ãªãã€Œãªãœãã®å‡¦ç†ãŒå¿…è¦ãªã®ã‹ã€ã€ã€Œã©ã®ã‚ˆã†ã«åˆ¤æ–­ã™ã¹ãã‹ã€ã¨ã„ã£ãŸæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã«ã‚‚ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚

## ç›®æ¬¡
- ã¯ã˜ã‚ã«
- ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã¯
- çµ±è¨ˆå­¦çš„è¦–ç‚¹ã‹ã‚‰è¦‹ãŸãƒ¢ãƒ‡ãƒ«è©•ä¾¡
- è©•ä¾¡æŒ‡æ¨™ã®ç†è«–çš„èƒŒæ™¯
  - â„¹ï¸å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™
  - â„¹ï¸åˆ†é¡å•é¡Œã®è©•ä¾¡æŒ‡æ¨™
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
  - â„¹ï¸ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
  - â„¹ï¸ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
  - â„¹ï¸ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
- äº¤å·®æ¤œè¨¼ã®é«˜åº¦ãªæ‰‹æ³•
- ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ã¨èª¬æ˜å¯èƒ½æ€§
- Pythonã‚’ç”¨ã„ãŸå®Ÿè·µ
- ã¾ã¨ã‚

## ã¯ã˜ã‚ã«

æœ¬ã‚·ãƒªãƒ¼ã‚ºã§ã¯å…¨6ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã¦ã€çµ±è¨ˆå­¦ã¨æ©Ÿæ¢°å­¦ç¿’ã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦è§£èª¬ã—ã¦ã„ã¾ã™ã€‚

1. æ¦‚è¦
2. æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ(EDA)
3. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
4. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
5. ãƒ¢ãƒ‡ãƒ«é¸å®šã¨å­¦ç¿’
6. **ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**

ç¬¬5å›ã€Œãƒ¢ãƒ‡ãƒ«é¸å®šã¨å­¦ç¿’ç·¨ã€ã§ã¯ã€é©åˆ‡ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸æŠã¨å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã—ãŸã€‚
ä»Šå›ã¯æœ€çµ‚å›ã¨ã—ã¦ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å®¢è¦³çš„ã«è©•ä¾¡ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹æ‰‹æ³•ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

## ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã¯

ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆModel Evaluationï¼‰ã¨ã¯ã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ€§èƒ½ã‚’å®šé‡çš„ã«æ¸¬å®šã—ã€å®Ÿç”¨æ€§ã‚’åˆ¤æ–­ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚
ãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆModel Tuningï¼‰ã¨ã¯ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æœ€é©åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚

### ãªãœé©åˆ‡ãªè©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé‡è¦ãªã®ã‹

1. **æ±åŒ–æ€§èƒ½ã®æ­£ç¢ºãªæŠŠæ¡**ï¼šæœªè¦‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹çœŸã®æ€§èƒ½ã‚’æ¨å®š
2. **éå­¦ç¿’ã®æ¤œå‡º**ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆã—ã¦ã„ãªã„ã‹ã®ç¢ºèª
3. **ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®å®šé‡åŒ–**ï¼šå®Ÿéš›ã®æ¥­å‹™ã«ãŠã‘ã‚‹ä¾¡å€¤ã®æ¸¬å®š
4. **ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã®æ–¹å‘æ€§**ï¼šæ€§èƒ½å‘ä¸Šã®ãŸã‚ã®å…·ä½“çš„ãªæ–½ç­–ã®ç‰¹å®š

## çµ±è¨ˆå­¦çš„è¦–ç‚¹ã‹ã‚‰è¦‹ãŸãƒ¢ãƒ‡ãƒ«è©•ä¾¡

### çµ±è¨ˆçš„æ¨è«–ã®è¦³ç‚¹

æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹è©•ä¾¡ã¯ã€æœ¬è³ªçš„ã«çµ±è¨ˆçš„æ¨è«–ã®å•é¡Œã§ã™ã€‚
é™ã‚‰ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰æ¯é›†å›£ã®æ€§è³ªã‚’æ¨å®šã—ã€ä¿¡é ¼åŒºé–“ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚

**æ¨å®šã®ä¸åæ€§**
```
E[Î¸Ì‚] = Î¸ (çœŸã®å€¤)
```

**æ¨å®šã®ä¸€è‡´æ€§**
```
lim P(|Î¸Ì‚n - Î¸| > Îµ) = 0
nâ†’âˆ
```

### è©•ä¾¡ã«ãŠã‘ã‚‹çµ±è¨ˆçš„ä»®å®š

**ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆi.i.d.ï¼‰ä»®å®š**
- å„ã‚µãƒ³ãƒ—ãƒ«ãŒç‹¬ç«‹
- åŒä¸€ã®åˆ†å¸ƒã‹ã‚‰ç”Ÿæˆ

**ä»£è¡¨æ€§ã®ä»®å®š**
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒåŒä¸€åˆ†å¸ƒ
- æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ã¨ã®åˆ†å¸ƒä¸€è‡´

## è©•ä¾¡æŒ‡æ¨™ã®ç†è«–çš„èƒŒæ™¯

### â„¹ï¸å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™

#### å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰
```
MSE = (1/n) Î£(yi - Å·i)Â²
```

**çµ±è¨ˆå­¦çš„æ„å‘³**
- ä¸åæ¨å®šé‡ï¼ˆãƒã‚¤ã‚¢ã‚¹ãŒãªã„å ´åˆï¼‰
- å¤–ã‚Œå€¤ã«æ•æ„Ÿ
- æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ãŸæœ€å°¤æ¨å®šã«å¯¾å¿œ

#### å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰
```
MAE = (1/n) Î£|yi - Å·i|
```

**çµ±è¨ˆå­¦çš„æ„å‘³**
- ä¸­å¤®å€¤ã®æœ€é©æ¨å®šé‡
- å¤–ã‚Œå€¤ã«é ‘å¥
- ãƒ©ãƒ—ãƒ©ã‚¹åˆ†å¸ƒã‚’ä»®å®šã—ãŸæœ€å°¤æ¨å®šã«å¯¾å¿œ

#### æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰
```
RÂ² = 1 - (SS_res / SS_tot)
```
```
SS_res = Î£(yi - Å·i)Â²
SS_tot = Î£(yi - È³)Â²
```

**çµ±è¨ˆå­¦çš„æ„å‘³**
- èª¬æ˜ã§ãã‚‹åˆ†æ•£ã®å‰²åˆ
- 0ã‹ã‚‰1ã®ç¯„å›²ï¼ˆè² å€¤ã‚‚å¯èƒ½ï¼‰
- ç›¸é–¢ä¿‚æ•°ã®äºŒä¹—ã¨ã—ã¦è§£é‡ˆå¯èƒ½

#### å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ï¼ˆMAPEï¼‰
```
MAPE = (100/n) Î£|((yi - Å·i) / yi)|
```

**é©ç”¨æ¡ä»¶**
- ç›®çš„å¤‰æ•°ãŒæ­£ã®å€¤ã®ã¿
- ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è§£é‡ˆãŒé‡è¦ãªå ´åˆ

### â„¹ï¸åˆ†é¡å•é¡Œã®è©•ä¾¡æŒ‡æ¨™

#### æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰

|         | äºˆæ¸¬Positive | äºˆæ¸¬Negative |
|---------|-------------|-------------|
| å®Ÿéš›Positive | TP | FN |
| å®Ÿéš›Negative | FP | TN |

#### ç²¾åº¦ï¼ˆAccuracyï¼‰
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

#### é©åˆç‡ï¼ˆPrecisionï¼‰
```
Precision = TP / (TP + FP)
```

#### å†ç¾ç‡ï¼ˆRecallï¼‰
```
Recall = TP / (TP + FN)
```

#### F1ã‚¹ã‚³ã‚¢
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**çµ±è¨ˆå­¦çš„è§£é‡ˆ**
- ç²¾åº¦ã¨å†ç¾ç‡ã®èª¿å’Œå¹³å‡
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨

#### ROCæ›²ç·šã¨AUC

**ROCæ›²ç·š**ï¼šçœŸé™½æ€§ç‡ï¼ˆTPRï¼‰ã¨å½é™½æ€§ç‡ï¼ˆFPRï¼‰ã®é–¢ä¿‚
```
TPR = TP / (TP + FN)
FPR = FP / (FP + TN)
```

**AUCï¼ˆArea Under Curveï¼‰**
- 0.5ã‹ã‚‰1.0ã®ç¯„å›²
- 0.5ï¼šãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬
- 1.0ï¼šå®Œå…¨äºˆæ¸¬

**çµ±è¨ˆå­¦çš„æ„å‘³**
- ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã æ­£ä¾‹ã¨è² ä¾‹ã®ãƒšã‚¢ã§ã€æ­£ä¾‹ã«ã‚ˆã‚Šé«˜ã„ã‚¹ã‚³ã‚¢ãŒä»˜ãç¢ºç‡

## ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### â„¹ï¸ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ

å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã‚’ç¶²ç¾…çš„ã«æ¢ç´¢ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚

**åˆ©ç‚¹**
- ç¢ºå®Ÿã«æœ€é©è§£ã‚’ç™ºè¦‹
- å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’æŠŠæ¡å¯èƒ½

**æ¬ ç‚¹**
- è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæŒ‡æ•°çš„ã«å¢—åŠ 
- æ¬¡å…ƒã®å‘ªã„

### â„¹ï¸ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚

**çµ±è¨ˆå­¦çš„æ ¹æ‹ **
- é«˜æ¬¡å…ƒã«ãŠã„ã¦åŠ¹ç‡çš„
- é‡è¦ã§ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’å‰Šæ¸›

**é©ç”¨æ¡ä»¶**
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„å ´åˆ
- è¨ˆç®—è³‡æºãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆ

### â„¹ï¸ãƒ™ã‚¤ã‚ºæœ€é©åŒ–

ã‚¬ã‚¦ã‚¹éç¨‹ã‚’ç”¨ã„ã¦åŠ¹ç‡çš„ã«æœ€é©åŒ–ã‚’è¡Œã†æ‰‹æ³•ã§ã™ã€‚

**çµ±è¨ˆå­¦çš„èƒŒæ™¯**
- ãƒ™ã‚¤ã‚ºçµ±è¨ˆã«åŸºã¥ãä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ–
- ç²å¾—é–¢æ•°ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªæ¢ç´¢

**ç²å¾—é–¢æ•°ã®ä¾‹**
- Expected Improvementï¼ˆEIï¼‰
- Upper Confidence Boundï¼ˆUCBï¼‰
- Probability of Improvementï¼ˆPIï¼‰

## äº¤å·®æ¤œè¨¼ã®é«˜åº¦ãªæ‰‹æ³•

### å±¤åŒ–äº¤å·®æ¤œè¨¼ï¼ˆStratified CVï¼‰

ã‚¯ãƒ©ã‚¹ã®æ¯”ç‡ã‚’ä¿æŒã—ãŸäº¤å·®æ¤œè¨¼ã§ã™ã€‚

**é©ç”¨æ¡ä»¶**
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- åˆ†é¡å•é¡Œ

### æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ï¼ˆTime Series CVï¼‰

æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸäº¤å·®æ¤œè¨¼ã§ã™ã€‚

**ç‰¹å¾´**
- æœªæ¥ã®æƒ…å ±ã‚’ä½¿ç”¨ã—ãªã„
- æ™‚é–“çš„ãªé †åºã‚’ä¿æŒ

### ç¾¤äº¤å·®æ¤œè¨¼ï¼ˆGroup CVï¼‰

é–¢é€£ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¦æ‰±ã†äº¤å·®æ¤œè¨¼ã§ã™ã€‚

**é©ç”¨ä¾‹**
- æ‚£è€…ãƒ‡ãƒ¼ã‚¿ï¼ˆåŒä¸€æ‚£è€…ã®è¤‡æ•°æ¸¬å®šï¼‰
- åœ°ç†çš„ãƒ‡ãƒ¼ã‚¿ï¼ˆåŒä¸€åœ°åŸŸã®è¤‡æ•°è¦³æ¸¬ï¼‰

## ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ã¨èª¬æ˜å¯èƒ½æ€§

### SHAPï¼ˆSHapley Additive exPlanationsï¼‰

ã‚²ãƒ¼ãƒ ç†è«–ã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚¤å€¤ã«åŸºã¥ãç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—æ‰‹æ³•ã§ã™ã€‚

**çµ±è¨ˆå­¦çš„èƒŒæ™¯**
- å„ç‰¹å¾´é‡ã®é™ç•Œçš„è²¢çŒ®åº¦ã‚’è¨ˆç®—
- åŠ æ³•æ€§ã‚’æº€ãŸã™å”¯ä¸€ã®æ‰‹æ³•

### LIMEï¼ˆLocal Interpretable Model-agnostic Explanationsï¼‰

å±€æ‰€çš„ãªç·šå½¢è¿‘ä¼¼ã«ã‚ˆã‚‹èª¬æ˜æ‰‹æ³•ã§ã™ã€‚

**ç‰¹å¾´**
- ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„
- å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜

### é †åˆ—é‡è¦åº¦ï¼ˆPermutation Importanceï¼‰

ç‰¹å¾´é‡ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å…¥ã‚Œæ›¿ãˆãŸéš›ã®æ€§èƒ½åŠ£åŒ–ã‚’æ¸¬å®šã™ã‚‹æ‰‹æ³•ã§ã™ã€‚

**çµ±è¨ˆå­¦çš„è§£é‡ˆ**
- å› æœé–¢ä¿‚ã§ã¯ãªãé–¢é€£æ€§ã‚’æ¸¬å®š
- ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„æ‰‹æ³•

## Pythonã‚’ç”¨ã„ãŸå®Ÿè·µ

diamondsãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚¢ã‚¤ãƒªã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

### å›å¸°å•é¡Œã®è©³ç´°è©•ä¾¡

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV, 
                                   RandomizedSearchCV, TimeSeriesSplit, StratifiedKFold)
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,
                           mean_absolute_percentage_error, make_scorer)
from sklearn.preprocessing import StandardScaler
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
df = sns.load_dataset('diamonds')

# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
cut_order = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}
color_order = {'J': 1, 'I': 2, 'H': 3, 'G': 4, 'F': 5, 'E': 6, 'D': 7}
clarity_order = {'I1': 1, 'SI2': 2, 'SI1': 3, 'VS2': 4, 'VS1': 5, 'VVS2': 6, 'VVS1': 7, 'IF': 8, 'FL': 9}

df['cut_encoded'] = df['cut'].map(cut_order)
df['color_encoded'] = df['color'].map(color_order)
df['clarity_encoded'] = df['clarity'].map(clarity_order)

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
df['volume'] = df['x'] * df['y'] * df['z']
df['density'] = df['carat'] / (df['volume'] + 1e-8)

features = ['carat', 'cut_encoded', 'color_encoded', 'clarity_encoded', 'depth', 'table', 'volume', 'density']
X = df[features]
y = df['price']

# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆè¨ˆç®—æ™‚é–“çŸ­ç¸®ã®ãŸã‚ï¼‰
X_sample, _, y_sample, _ = train_test_split(X, y, train_size=0.1, random_state=42)

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: è¨“ç·´={X_train.shape}, ãƒ†ã‚¹ãƒˆ={X_test.shape}")
```

### è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã«ã‚ˆã‚‹åŒ…æ‹¬çš„è©•ä¾¡

```python
# ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡é–¢æ•°ã®å®šç¾©
def calculate_regression_metrics(y_true, y_pred):
    """å›å¸°å•é¡Œã®åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—"""
    metrics = {
        'MSE': mean_squared_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'RÂ²': r2_score(y_true, y_pred),
        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100
    }
    
    # èª¿æ•´æ¸ˆã¿æ±ºå®šä¿‚æ•°
    n = len(y_true)
    p = X_train.shape[1]  # ç‰¹å¾´é‡æ•°
    metrics['Adjusted_RÂ²'] = 1 - (1 - metrics['RÂ²']) * (n - 1) / (n - p - 1)
    
    return metrics

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
models = {
    'Ridge': Ridge(alpha=1.0, random_state=42),
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

baseline_results = {}

for name, model in models.items():
    if name == 'Ridge':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    
    baseline_results[name] = calculate_regression_metrics(y_test, y_pred)

# çµæœã®è¡¨ç¤º
baseline_df = pd.DataFrame(baseline_results).T
print("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡çµæœ:")
print(baseline_df.round(4))

# çµæœã®å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.ravel()

metrics = ['MSE', 'RMSE', 'MAE', 'RÂ²', 'Adjusted_RÂ²', 'MAPE']

for i, metric in enumerate(metrics):
    values = baseline_df[metric]
    axes[i].bar(values.index, values)
    axes[i].set_title(f'{metric} Comparison')
    axes[i].set_ylabel(metric)
    axes[i].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
```

### çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œå®š

```python
# äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹çµ±è¨ˆçš„è©•ä¾¡
def cross_validate_model(model, X, y, cv=5, scoring='r2'):
    """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨çµ±è¨ˆçš„æ¤œå®š"""
    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
    
    # çµ±è¨ˆçš„è¦ç´„
    stats_summary = {
        'mean': scores.mean(),
        'std': scores.std(),
        'min': scores.min(),
        'max': scores.max(),
        'median': np.median(scores),
        'confidence_interval_95': stats.t.interval(0.95, len(scores)-1, 
                                                 loc=scores.mean(), 
                                                 scale=stats.sem(scores))
    }
    
    return scores, stats_summary

# å„ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
cv_results = {}

for name, model in models.items():
    print(f"\n{name}ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
    
    if name == 'Ridge':
        scores, summary = cross_validate_model(model, X_train_scaled, y_train)
    else:
        scores, summary = cross_validate_model(model, X_train, y_train)
    
    cv_results[name] = {'scores': scores, 'summary': summary}
    
    print(f"RÂ²ã‚¹ã‚³ã‚¢: {summary['mean']:.4f} Â± {summary['std']:.4f}")
    print(f"95%ä¿¡é ¼åŒºé–“: [{summary['confidence_interval_95'][0]:.4f}, {summary['confidence_interval_95'][1]:.4f}]")

# çµ±è¨ˆçš„æœ‰æ„å·®æ¤œå®šï¼ˆå¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼‰
from scipy.stats import ttest_rel

model_names = list(cv_results.keys())
print("\nãƒ¢ãƒ‡ãƒ«é–“ã®çµ±è¨ˆçš„æœ‰æ„å·®æ¤œå®šï¼ˆå¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼‰:")

for i in range(len(model_names)):
    for j in range(i+1, len(model_names)):
        model1, model2 = model_names[i], model_names[j]
        scores1 = cv_results[model1]['scores']
        scores2 = cv_results[model2]['scores']
        
        t_stat, p_value = ttest_rel(scores1, scores2)
        
        print(f"{model1} vs {model2}:")
        print(f"  tçµ±è¨ˆé‡: {t_stat:.4f}, på€¤: {p_value:.4f}")
        if p_value < 0.05:
            print(f"  â†’ æœ‰æ„å·®ã‚ã‚Š (p < 0.05)")
        else:
            print(f"  â†’ æœ‰æ„å·®ãªã— (p â‰¥ 0.05)")
```

### ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

```python
# Random Forestã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
rf_param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None]
}

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®å®Ÿè¡Œ
rf_grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42),
    rf_param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

print("Random Forestã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå®Ÿè¡Œä¸­...")
rf_grid_search.fit(X_train, y_train)

print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {rf_grid_search.best_params_}")
print(f"æœ€è‰¯CV ã‚¹ã‚³ã‚¢: {rf_grid_search.best_score_:.4f}")

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒçµæœã®è©³ç´°åˆ†æ
rf_results = pd.DataFrame(rf_grid_search.cv_results_)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã®æ€§èƒ½åˆ†æ
plt.figure(figsize=(15, 10))

# n_estimatorsã®å½±éŸ¿
plt.subplot(2, 3, 1)
n_est_scores = rf_results.groupby('param_n_estimators')['mean_test_score'].mean()
plt.bar(range(len(n_est_scores)), n_est_scores.values)
plt.xticks(range(len(n_est_scores)), n_est_scores.index)
plt.xlabel('n_estimators')
plt.ylabel('Mean CV Score')
plt.title('Impact of n_estimators')

# max_depthã®å½±éŸ¿
plt.subplot(2, 3, 2)
depth_scores = rf_results.groupby('param_max_depth')['mean_test_score'].mean()
plt.bar(range(len(depth_scores)), depth_scores.values)
plt.xticks(range(len(depth_scores)), [str(x) for x in depth_scores.index])
plt.xlabel('max_depth')
plt.ylabel('Mean CV Score')
plt.title('Impact of max_depth')

# min_samples_splitã®å½±éŸ¿
plt.subplot(2, 3, 3)
split_scores = rf_results.groupby('param_min_samples_split')['mean_test_score'].mean()
plt.bar(range(len(split_scores)), split_scores.values)
plt.xticks(range(len(split_scores)), split_scores.index)
plt.xlabel('min_samples_split')
plt.ylabel('Mean CV Score')
plt.title('Impact of min_samples_split')

# å­¦ç¿’æ›²ç·švsæ¤œå®šæ›²ç·š
plt.subplot(2, 3, 4)
train_scores = rf_results['mean_train_score']
test_scores = rf_results['mean_test_score']
plt.scatter(train_scores, test_scores, alpha=0.6)
plt.plot([train_scores.min(), train_scores.max()], 
         [train_scores.min(), train_scores.max()], 'r--', linewidth=2)
plt.xlabel('Training Score')
plt.ylabel('Validation Score')
plt.title('Training vs Validation Score')

# ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹åˆ†æ
plt.subplot(2, 3, 5)
plt.scatter(rf_results['mean_train_score'] - rf_results['mean_test_score'], 
           rf_results['mean_test_score'], alpha=0.6)
plt.xlabel('Training - Validation Score')
plt.ylabel('Validation Score')
plt.title('Bias-Variance Analysis')
plt.axvline(x=0, color='r', linestyle='--')

plt.tight_layout()
plt.show()

# æœ€é©ãƒ¢ãƒ‡ãƒ«ã§ã®æœ€çµ‚è©•ä¾¡
best_rf = rf_grid_search.best_estimator_
y_pred_best_rf = best_rf.predict(X_test)
final_metrics = calculate_regression_metrics(y_test, y_pred_best_rf)

print("\næœ€é©åŒ–å¾ŒRandom Forestã®æœ€çµ‚è©•ä¾¡:")
for metric, value in final_metrics.items():
    print(f"{metric}: {value:.4f}")
```

### ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®å®Ÿè¡Œ
rf_random_param = {
    'n_estimators': randint(50, 300),
    'max_depth': [None] + list(randint(5, 50).rvs(10)),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': ['sqrt', 'log2', None]
}

rf_random_search = RandomizedSearchCV(
    RandomForestRegressor(random_state=42),
    rf_random_param,
    n_iter=50,  # 50å›ã®è©¦è¡Œ
    cv=5,
    scoring='r2',
    n_jobs=-1,
    random_state=42,
    return_train_score=True
)

print("Random Forestã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒå®Ÿè¡Œä¸­...")
rf_random_search.fit(X_train, y_train)

print(f"ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {rf_random_search.best_params_}")
print(f"ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒæœ€è‰¯CVã‚¹ã‚³ã‚¢: {rf_random_search.best_score_:.4f}")

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒvsãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®æ¯”è¼ƒ
comparison_results = {
    'Grid Search': {
        'best_score': rf_grid_search.best_score_,
        'n_trials': len(rf_grid_search.cv_results_['mean_test_score']),
        'best_params': rf_grid_search.best_params_
    },
    'Random Search': {
        'best_score': rf_random_search.best_score_,
        'n_trials': len(rf_random_search.cv_results_['mean_test_score']),
        'best_params': rf_random_search.best_params_
    }
}

print("\nã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ vs ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒæ¯”è¼ƒ:")
for method, results in comparison_results.items():
    print(f"\n{method}:")
    print(f"  æœ€è‰¯ã‚¹ã‚³ã‚¢: {results['best_score']:.4f}")
    print(f"  è©¦è¡Œå›æ•°: {results['n_trials']}")
    print(f"  æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {results['best_params']}")

# åŠ¹ç‡æ€§ã®å¯è¦–åŒ–
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
grid_scores = rf_grid_search.cv_results_['mean_test_score']
plt.plot(range(len(grid_scores)), sorted(grid_scores, reverse=True), 'b-', label='Grid Search')
plt.xlabel('Number of Trials')
plt.ylabel('Best Score So Far')
plt.title('Grid Search Progress')
plt.grid(True)

plt.subplot(1, 2, 2)
random_scores = rf_random_search.cv_results_['mean_test_score']
cumulative_best = np.maximum.accumulate(sorted(random_scores, reverse=True))
plt.plot(range(len(cumulative_best)), cumulative_best, 'r-', label='Random Search')
plt.xlabel('Number of Trials')
plt.ylabel('Best Score So Far')
plt.title('Random Search Progress')
plt.grid(True)

plt.tight_layout()
plt.show()
```

### å­¦ç¿’æ›²ç·šã¨æ¤œè¨¼æ›²ç·š

```python
from sklearn.model_selection import learning_curve, validation_curve

# å­¦ç¿’æ›²ç·šã®æç”»
def plot_learning_curves(model, X, y, title="Learning Curves"):
    """å­¦ç¿’æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    train_sizes, train_scores, val_scores = learning_curve(
        model, X, y, cv=5, n_jobs=-1, 
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='r2', random_state=42
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, 
                     alpha=0.1, color='blue')
    
    plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, 
                     alpha=0.1, color='red')
    
    plt.xlabel('Training Set Size')
    plt.ylabel('RÂ² Score')
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.show()
    
    return train_sizes, train_scores, val_scores

# æ¤œè¨¼æ›²ç·šã®æç”»
def plot_validation_curve(model, X, y, param_name, param_range, title="Validation Curve"):
    """æ¤œè¨¼æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    train_scores, val_scores = validation_curve(
        model, X, y, param_name, param_range, cv=5, 
        scoring='r2', n_jobs=-1
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(param_range, train_mean, 'o-', color='blue', label='Training Score')
    plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, 
                     alpha=0.1, color='blue')
    
    plt.plot(param_range, val_mean, 'o-', color='red', label='Validation Score')
    plt.fill_between(param_range, val_mean - val_std, val_mean + val_std, 
                     alpha=0.1, color='red')
    
    plt.xlabel(param_name)
    plt.ylabel('RÂ² Score')
    plt.title(title)
    plt.legend()
    plt.grid(True)
    if param_name in ['alpha', 'C']:
        plt.xscale('log')
    plt.show()

# Random Forestã®å­¦ç¿’æ›²ç·š
print("Random Forestã®å­¦ç¿’æ›²ç·šã‚’æç”»ä¸­...")
plot_learning_curves(
    RandomForestRegressor(n_estimators=100, random_state=42),
    X_train, y_train,
    "Random Forest Learning Curves"
)

# n_estimatorsã®æ¤œè¨¼æ›²ç·š
print("n_estimatorsã®æ¤œè¨¼æ›²ç·šã‚’æç”»ä¸­...")
plot_validation_curve(
    RandomForestRegressor(random_state=42),
    X_train, y_train,
    'n_estimators',
    [10, 25, 50, 75, 100, 150, 200, 250, 300],
    "Validation Curve: n_estimators"
)

# max_depthã®æ¤œè¨¼æ›²ç·š
print("max_depthã®æ¤œè¨¼æ›²ç·šã‚’æç”»ä¸­...")
plot_validation_curve(
    RandomForestRegressor(n_estimators=100, random_state=42),
    X_train, y_train,
    'max_depth',
    [3, 5, 7, 10, 15, 20, 25, 30, None],
    "Validation Curve: max_depth"
)
```

### ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§åˆ†æ

```python
# SHAPå€¤ã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
try:
    import shap
    
    # æœ€é©åŒ–ã•ã‚ŒãŸRandom Forestãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    explainer = shap.TreeExplainer(best_rf)
    shap_values = explainer.shap_values(X_test[:100])  # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™
    
    # SHAP Summary Plot
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X_test[:100], feature_names=features, show=False)
    plt.title('SHAP Summary Plot')
    plt.tight_layout()
    plt.show()
    
    # ç‰¹å¾´é‡é‡è¦åº¦ã®æ¯”è¼ƒ
    shap_importance = np.abs(shap_values).mean(0)
    rf_importance = best_rf.feature_importances_
    
    importance_comparison = pd.DataFrame({
        'feature': features,
        'SHAP_importance': shap_importance,
        'RF_importance': rf_importance
    }).sort_values('SHAP_importance', ascending=False)
    
    print("ç‰¹å¾´é‡é‡è¦åº¦ã®æ¯”è¼ƒ:")
    print(importance_comparison.round(4))
    
    # é‡è¦åº¦ã®å¯è¦–åŒ–
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    plt.barh(importance_comparison['feature'], importance_comparison['SHAP_importance'])
    plt.xlabel('SHAP Importance')
    plt.title('SHAP Feature Importance')
    plt.gca().invert_yaxis()
    
    plt.subplot(1, 2, 2)
    plt.barh(importance_comparison['feature'], importance_comparison['RF_importance'])
    plt.xlabel('Random Forest Importance')
    plt.title('Random Forest Feature Importance')
    plt.gca().invert_yaxis()
    
    plt.tight_layout()
    plt.show()
    
except ImportError:
    print("SHAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("pip install shap ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")

# é †åˆ—é‡è¦åº¦ã®è¨ˆç®—
from sklearn.inspection import permutation_importance

perm_importance = permutation_importance(
    best_rf, X_test, y_test, n_repeats=10, random_state=42, scoring='r2'
)

perm_importance_df = pd.DataFrame({
    'feature': features,
    'importance_mean': perm_importance.importances_mean,
    'importance_std': perm_importance.importances_std
}).sort_values('importance_mean', ascending=False)

print("\né †åˆ—é‡è¦åº¦:")
print(perm_importance_df.round(4))

# é †åˆ—é‡è¦åº¦ã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.barh(perm_importance_df['feature'], perm_importance_df['importance_mean'],
         xerr=perm_importance_df['importance_std'])
plt.xlabel('Permutation Importance')
plt.title('Permutation Feature Importance')
plt.gca().invert_yaxis()
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()
```

### åˆ†é¡å•é¡Œã§ã®è©•ä¾¡ï¼ˆãƒœãƒ¼ãƒŠã‚¹ï¼‰

```python
# ã‚¢ã‚¤ãƒªã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®åˆ†é¡å•é¡Œè©•ä¾¡
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (classification_report, confusion_matrix, 
                           roc_auc_score, roc_curve, precision_recall_curve,
                           average_precision_score)
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
iris = load_iris()
X_iris, y_iris = iris.data, iris.target

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(
    X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris
)

# Random Foreståˆ†é¡å™¨
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train_iris, y_train_iris)

# äºˆæ¸¬ã¨äºˆæ¸¬ç¢ºç‡
y_pred_iris = rf_clf.predict(X_test_iris)
y_prob_iris = rf_clf.predict_proba(X_test_iris)

# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
print("åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_report(y_test_iris, y_pred_iris, target_names=iris.target_names))

# æ··åŒè¡Œåˆ—
cm = confusion_matrix(y_test_iris, y_pred_iris)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
           xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# ROCæ›²ç·šï¼ˆå¤šã‚¯ãƒ©ã‚¹ï¼‰
y_test_bin = label_binarize(y_test_iris, classes=[0, 1, 2])
n_classes = y_test_bin.shape[1]

plt.figure(figsize=(12, 4))

for i in range(n_classes):
    plt.subplot(1, 3, i+1)
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob_iris[:, i])
    auc_score = roc_auc_score(y_test_bin[:, i], y_prob_iris[:, i])
    
    plt.plot(fpr, tpr, linewidth=2, label=f'ROC curve (AUC = {auc_score:.2f})')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve: {iris.target_names[i]}')
    plt.legend(loc="lower right")
    plt.grid(True)

plt.tight_layout()
plt.show()

print(f"ãƒã‚¯ãƒ­å¹³å‡AUC: {roc_auc_score(y_test_bin, y_prob_iris, multi_class='ovr', average='macro'):.4f}")
print(f"é‡ã¿ä»˜ãå¹³å‡AUC: {roc_auc_score(y_test_bin, y_prob_iris, multi_class='ovr', average='weighted'):.4f}")
```

### æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ

```python
# æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
def generate_model_report(model, X_train, X_test, y_train, y_test, model_name):
    """åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    
    # äºˆæ¸¬
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
    train_metrics = calculate_regression_metrics(y_train, y_pred_train)
    test_metrics = calculate_regression_metrics(y_test, y_pred_test)
    
    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
    
    report = {
        'Model': model_name,
        'Training_RÂ²': train_metrics['RÂ²'],
        'Test_RÂ²': test_metrics['RÂ²'],
        'CV_RÂ²_mean': cv_scores.mean(),
        'CV_RÂ²_std': cv_scores.std(),
        'Training_RMSE': train_metrics['RMSE'],
        'Test_RMSE': test_metrics['RMSE'],
        'Overfitting_Gap': train_metrics['RÂ²'] - test_metrics['RÂ²'],
        'Generalization_Score': test_metrics['RÂ²'] / train_metrics['RÂ²'] if train_metrics['RÂ²'] > 0 else 0
    }
    
    return report

# æœ€é©åŒ–å¾Œã®å…¨ãƒ¢ãƒ‡ãƒ«ã§æœ€çµ‚è©•ä¾¡
final_models = {
    'Optimized_RandomForest': best_rf,
    'Ridge_Baseline': Ridge(alpha=1.0, random_state=42),
    'GradientBoosting_Baseline': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

final_reports = []

for name, model in final_models.items():
    if 'Ridge' in name:
        # Ridgeã¯æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        model.fit(X_train_scaled, y_train)
        report = generate_model_report(model, X_train_scaled, X_test_scaled, y_train, y_test, name)
    else:
        model.fit(X_train, y_train)
        report = generate_model_report(model, X_train, X_test, y_train, y_test, name)
    
    final_reports.append(report)

# æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
final_report_df = pd.DataFrame(final_reports)
final_report_df = final_report_df.sort_values('Test_RÂ²', ascending=False)

print("æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print("=" * 80)
for _, row in final_report_df.iterrows():
    print(f"\nãƒ¢ãƒ‡ãƒ«: {row['Model']}")
    print(f"ãƒ†ã‚¹ãƒˆRÂ²: {row['Test_RÂ²']:.4f}")
    print(f"ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³RÂ²: {row['CV_RÂ²_mean']:.4f} Â± {row['CV_RÂ²_std']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆRMSE: {row['Test_RMSE']:.2f}")
    print(f"éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: {row['Overfitting_Gap']:.4f}")
    print(f"æ±åŒ–ã‚¹ã‚³ã‚¢: {row['Generalization_Score']:.4f}")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸å®š
best_final_model = final_report_df.iloc[0]
print(f"\nğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_final_model['Model']}")
print(f"   ãƒ†ã‚¹ãƒˆæ€§èƒ½: RÂ² = {best_final_model['Test_RÂ²']:.4f}, RMSE = {best_final_model['Test_RMSE']:.2f}")
print(f"   æ±åŒ–èƒ½åŠ›: {best_final_model['Generalization_Score']:.4f}")

# æœ€çµ‚å¯è¦–åŒ–
plt.figure(figsize=(15, 10))

# æ€§èƒ½æ¯”è¼ƒ
plt.subplot(2, 3, 1)
plt.bar(final_report_df['Model'], final_report_df['Test_RÂ²'])
plt.ylabel('Test RÂ²')
plt.title('Model Performance Comparison')
plt.xticks(rotation=45)

# éå­¦ç¿’åˆ†æ
plt.subplot(2, 3, 2)
plt.scatter(final_report_df['Training_RÂ²'], final_report_df['Test_RÂ²'])
plt.plot([0, 1], [0, 1], 'r--', linewidth=2)
plt.xlabel('Training RÂ²')
plt.ylabel('Test RÂ²')
plt.title('Training vs Test Performance')

# RMSEæ¯”è¼ƒ
plt.subplot(2, 3, 3)
training_rmse = [calculate_regression_metrics(y_train, model.predict(X_train if 'Ridge' not in name else X_train_scaled))['RMSE'] 
                for name, model in final_models.items()]
plt.scatter(training_rmse, final_report_df['Test_RMSE'])
plt.xlabel('Training RMSE')
plt.ylabel('Test RMSE')
plt.title('Training vs Test RMSE')

# æ±åŒ–èƒ½åŠ›
plt.subplot(2, 3, 4)
plt.bar(final_report_df['Model'], final_report_df['Generalization_Score'])
plt.ylabel('Generalization Score')
plt.title('Generalization Ability')
plt.xticks(rotation=45)

# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®‰å®šæ€§
plt.subplot(2, 3, 5)
plt.bar(final_report_df['Model'], final_report_df['CV_RÂ²_std'])
plt.ylabel('CV RÂ² Standard Deviation')
plt.title('Cross-validation Stability')
plt.xticks(rotation=45)

# ç·åˆã‚¹ã‚³ã‚¢ï¼ˆTest RÂ² - Overfitting Gapï¼‰
plt.subplot(2, 3, 6)
comprehensive_score = final_report_df['Test_RÂ²'] - np.abs(final_report_df['Overfitting_Gap'])
plt.bar(final_report_df['Model'], comprehensive_score)
plt.ylabel('Comprehensive Score')
plt.title('Comprehensive Performance\n(Test RÂ² - |Overfitting Gap|)')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()
```

## ã¾ã¨ã‚

ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æˆåŠŸã‚’æ±ºå®šã¥ã‘ã‚‹é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã§ã™ã€‚æœ¬è¨˜äº‹ã§ã¯çµ±è¨ˆå­¦çš„è¦–ç‚¹ã‹ã‚‰ï¼š

### è©•ä¾¡ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ

1. **è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã®æ´»ç”¨**ï¼šRÂ²ã€RMSEã€MAEãªã©å•é¡Œã«å¿œã˜ãŸé©åˆ‡ãªæŒ‡æ¨™é¸æŠ
2. **çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼**ï¼šä¿¡é ¼åŒºé–“ã‚„ä»®èª¬æ¤œå®šã«ã‚ˆã‚‹å®¢è¦³çš„ãªæ€§èƒ½è©•ä¾¡
3. **ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼šéå­¦ç¿’ã‚’é˜²ãæ±åŒ–æ€§èƒ½ã‚’æ­£ç¢ºã«æ¨å®š
4. **å­¦ç¿’æ›²ç·šãƒ»æ¤œè¨¼æ›²ç·š**ï¼šãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã®å¯è¦–åŒ–ã¨ç†è§£

### ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœçš„æ‰‹æ³•

1. **ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ**ï¼šå°è¦æ¨¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®ç¶²ç¾…çš„æ¢ç´¢
2. **ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ**ï¼šé«˜æ¬¡å…ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®åŠ¹ç‡çš„æ¢ç´¢
3. **ãƒ™ã‚¤ã‚ºæœ€é©åŒ–**ï¼šå°‘ãªã„è©¦è¡Œå›æ•°ã§ã®åŠ¹ç‡çš„æœ€é©åŒ–
4. **ã‚¢ãƒ¼ãƒªãƒ¼ã‚¹ãƒˆãƒƒãƒ”ãƒ³ã‚°**ï¼šéå­¦ç¿’ã®é˜²æ­¢

### ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§

1. **SHAPå€¤**ï¼šå€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜ã¨ç‰¹å¾´é‡ã®è²¢çŒ®åº¦
2. **é †åˆ—é‡è¦åº¦**ï¼šãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„ç‰¹å¾´é‡é‡è¦åº¦
3. **å­¦ç¿’æ›²ç·š**ï¼šãƒ‡ãƒ¼ã‚¿é‡ã¨æ€§èƒ½ã®é–¢ä¿‚æ€§

### çµ±è¨ˆå­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä¾¡å€¤

çµ±è¨ˆå­¦çš„çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã„ã¦ï¼š
- **å®¢è¦³çš„ãªåˆ¤æ–­åŸºæº–**ã®ç¢ºç«‹
- **éå­¦ç¿’ãƒªã‚¹ã‚¯ã®å®šé‡åŒ–**ã¨å¯¾ç­–
- **ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ä¿¡é ¼æ€§è©•ä¾¡**
- **ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®å®šé‡åŒ–**

ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

æœ¬ã‚·ãƒªãƒ¼ã‚ºã‚’é€šã˜ã¦ã€çµ±è¨ˆå­¦ã¨æ©Ÿæ¢°å­¦ç¿’ã®å¯†æ¥ãªé–¢ä¿‚æ€§ã¨ã€ç†è«–ã«åŸºã¥ã„ãŸå®Ÿè·µçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§ã‚’ã”ç†è§£ã„ãŸã ã‘ãŸã§ã—ã‚‡ã†ã‹ã€‚
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æˆåŠŸã«ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çŸ¥è­˜ã ã‘ã§ãªãã€çµ±è¨ˆå­¦çš„æ€è€ƒãŒä¸å¯æ¬ ã§ã™ã€‚

ãœã²ä»Šå¾Œã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã“ã‚Œã‚‰ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã€ã‚ˆã‚Šä¾¡å€¤ã®é«˜ã„æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«ãŠå½¹ç«‹ã¦ãã ã•ã„ã€‚

---

**ã‚·ãƒªãƒ¼ã‚ºå®Œçµ**

æœ¬ã‚·ãƒªãƒ¼ã‚ºã€Œçµ±è¨ˆå­¦ã‹ã‚‰ç´è§£ãæ©Ÿæ¢°å­¦ç¿’ã€ã‚’ãŠèª­ã¿ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
æ©Ÿæ¢°å­¦ç¿’ã®ç†è«–çš„èƒŒæ™¯ã‹ã‚‰å®Ÿè·µçš„ãªå®Ÿè£…ã¾ã§ã€çµ±è¨ˆå­¦ã®è¦–ç‚¹ã‹ã‚‰åŒ…æ‹¬çš„ã«è§£èª¬ã„ãŸã—ã¾ã—ãŸã€‚
ä»Šå¾Œã‚‚çš†æ§˜ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å­¦ç¿’ã«ãŠå½¹ç«‹ã¦ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚