# 【python】統計学から紐解く機械学習-➁探索的データ分析(EDA)-

本シリーズでは、統計学の視点から機械学習を紐解くことを主眼に、基礎的な理論とPythonを用いた実装例を交えて、実践的に解説していきます。アルゴリズムの仕組みや数式の背景だけでなく「なぜその処理が必要なのか」、「どのように判断すべきか」といった思考プロセスにも焦点を当てます。

## 目次
- はじめに
- 探索的データ分析（EDA）とは
- EDAの観点と統計学の関連性
  - ℹ️記述統計量の確認
  - ℹ️変数の尺度の確認
  - ℹ️量的変数分布確認
  - ℹ️質的変数の構成確認
  - ℹ️変数間の関係性の確認
  - ℹ️欠損値の検出
- Pythonを用いた実践

## はじめに

本シリーズでは全6ステップに分けて、統計学と機械学習の関係性について解説しています。

1. 概要
2. **探索的データ分析(EDA)**
3. データ前処理
4. 特徴量エンジニアリング
5. モデル選定と学習
6. モデル評価とチューニング

第1回「概要編」をまだご覧でない方は、以下のリンクからぜひご一読ください。  
【python】統計学から紐解く機械学習-➀概要-  
🔗　https://note.com/cograph_data/n/ne794ec55cf9b

## 探索的データ分析（EDA）とは

EDA（Exploratory Data Analysis／探索的データ分析）とは、機械学習モデルの構築に先立って、データの構造・特性・傾向を明らかにするために実施される初期分析のプロセスです。

EDAは単なる作業的プロセスではなく、分析者がデータに対して主体的に問いを立て、今後の分析方針や処理の方向性を検討するための重要な思考プロセスでもあります。この段階で得られた洞察は、前処理の方針決定、特徴量の選定、さらにはモデルの設計に直結するため、機械学習全体の成果に大きな影響を与えることになります。

## EDAの観点と統計学の関連性

EDAは統計的な視点で行うことで直感的な把握にとどまらず、客観的かつ定量的な分析が可能になります。
以下では統計学の概念を交えつつ、EDAで確認すべき代表的な観点について実務ベースで紹介します。

### ℹ️記述統計量の確認

以下の記述統計量は、データの傾向やばらつきを瞬時に、かつ定量的に把握するための基本的な手段です。

**平均値**： データの合計をデータ数で割った値。データの「中心的な傾向」を示す代表的な指標です。
- 算出方法：（データの合計/データ数）
- ※例：データが[2,9,8,3,3]の場合、(2+9+8+3+3)/5=5

**中央値**： データを昇順に並べた際の中央の値。平均値との違いは外れ値の影響を受けにくく、分布が偏っている場合の代表値として有効な点です。
- ※例：データが[2,5,7,11,15]の場合、7

**最頻値**： データの中で最も頻繁に出現する値。カテゴリデータや離散的な数値において、どの値が多いかを把握するのに適しています。
- ※例：データが[a,b,c,c,d]の場合、c

**最大値/最小値**：データの中で最も大きな値と最も小さな値です。全データの値の範囲がどこからどこまでなのか把握するのに適しています。
- ※例：データが[1,5,9,12,15]の場合、最大値は15、最小値は1

### ℹ️変数の尺度の確認

変数には尺度に種類があり、統計学において定義されています。
各変数の尺度を把握することで、今後のステップにおけるアプローチを検討することができます。
以下に変数の尺度と定義を示します。

**質的変数**

- **名義尺度**：データのカテゴリを区別するための尺度  
  ※例：性別（男性/女性）

- **順序尺度**：名義尺度の特徴に加え、値に大小関係がある尺度  
  ※例：満足度（1:満足、2:どちらともいえない、3：不満）

**量的変数**

- **間隔尺度**：順序尺度の特徴に加え、値の差にも意味がある。かつ、0は相対的な意味しか持たない  
  ※例：温度、偏差値、西暦

- **比例尺度**：間隔尺度の特徴に加え、0が絶対的な意味を持つ  
  ※例：値段、身長

### ℹ️量的変数分布確認

量的変数は値の大きさに応じて分布しています。
この分布を把握することで、外れ値や分布の偏りに対する今後のアプローチを検討することができます。確認方法には以下の種類があります。

**四分位数**：データを昇順に並べ、4等分したときの位置。小さい方から順に各地点をQ1(25%タイル)、Q2(50%タイル※中央値)、Q3(75%タイル)と呼びます。最小値/最大値と比較することで外れ値を確認することができます。Q1～Q3の範囲を「四分位範囲（IQR）」と呼びます。

**分散**：データの「ばらつき具合」を示します。
- 算出方法：(偏差^2)/平均値
- ※例：データが[2,9,8,3,3]の場合、分散は8.4

**用語**
- 偏差：平均と各データの離れ具合（各データの値-平均値）

**標準偏差**：単位を元のデータに合わせた際のデータのばらつきです。
- 算出方法：√分散（分散の平方根）
- ※例：データが[2,9,8,3,3]の場合、標準偏差は2.9

**ヒストグラム**：横軸に階級、縦軸に各階級ごとの度数をとるグラフで、視覚的にデータの分布を確認することができます。

**用語**
- 階級：データを値の範囲ごとに分割した区間のことを言います。
- 度数：各階級のデータの個数
- 外れ値：外れ値を切り分ける方法の一つに「四分位範囲（IQR）」を用いる手法があります。IQRの1.5倍を上下限として、そこから外れた値を外れ値とみなします。ただし、外れ値であることと異常値であることは別であり、機械学習モデルに学習させるかどうかも判断しなければなりません。

**箱ひげ図**：中央値・四分位数・外れ値などを表示したグラフで、値のばらつきと外れ値を一目で確認することができます。

### ℹ️質的変数の構成確認

質的変数において特定のカテゴリが極端に多い／少ない場合、分析や機械学習に偏りが生じる恐れがあるため、事前に各カテゴリの種類や割合を確認する必要があります。

確認方法には以下の種類があります。
- 棒グラフ/円グラフ

### ℹ️変数間の関係性の確認

変数同士の関係性を確認することで、多重共線性や冗長性のリスクを評価します。

**用語**
- **多重共線性**：説明変数間の相関が強い状態を指します。機械学習モデルの予測精度が落ちるなどのデメリットがあります。
- **冗長性**：変数間の情報が重複しており、分析や機械学習に寄与しないことを指します。計算コストが悪化するなどのデメリットがあります。

変数同士の尺度の違いによって確認方法が異なるため、ケース毎に分けて紹介します。

**量的変数 × 量的変数の比較**

**共分散**：2つの変数が同じ方向に動くか（正の関係）・逆の方向に動くか（負の関係）を示す。
- 算出方法：1つ目の変数をx,2つ目をyとしたとき  
  {(xの各データの値-xの平均値) × (yの各データの値-yの平均値)}の合計/データ数
- ※例：x=[2,9,8,3,3],y=[4,10,8,6,5]の場合、共分散は 6.0

**相関係数**：2つの変数の関係性の強さと方向を −1〜+1 の範囲で表す。
- 算出方法：1つ目の変数をx,2つ目をyとしたとき  
  共分散/(xの標準偏差 × yの標準偏差)
- ※例：x=[2,9,8,3,3],y=[4,10,8,6,5]の場合、相関係数は0.96

**散布図**：2つの変数の各データに対応する点をプロットすることで、データの分布や傾向を視覚的に把握することができます。

**質的変数×質的変数の比較**

- **クロス集計表**：2つの変数をそれぞれのカテゴリーで同時に分類し、その度数を集計した表。
- **積み上げ棒グラフ**：1つ目の変数の各カテゴリに対して、2つ目の変数の割合を上に積み上げ表現したグラフ。

**量的変数×質的変数の比較**

- **スウォームプロット**：カテゴリごとの個々のデータ点を重ならないようにずらして一列に可視化するプロット。
- **箱ひげ図**

### ℹ️欠損値の検出

欠損値は分析や機械学習の精度に影響するため、欠損値の有無は把握する必要があります。
また、単に有無を確認するだけでなく、「どの変数に」「どの程度の割合で」欠損が生じているのか、欠損値が及ぼす影響の度合いについて把握しておくことが重要です。

## Pythonを用いた実践

ここでは、オープンデータを使用してPythonでのEDAの実践を行います。

- **データセット**： seaborn「diamonds」
- **目的**：ダイヤモンドの各特徴から価格を予測する

以下にコードの実行例と出力、各項目でのチェックポイントを示します。

### データの読み込み、ライブラリのインポート

```python
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = sns.load_dataset('diamonds')
```

### データの内容把握

```python
df.head()
```

ここでは、各カラムにどのような値が存在するのか大まかに把握します。
また、この時に各カラムの定義についても把握します。
データの提供元から正確な情報を取得してください。
https://ggplot2.tidyverse.org/reference/diamonds.html

### データセットの概要の把握

```python
df.info()
```

ここではデータセットの概要を把握します。確認するポイントは以下です。
- **データの大きさ**：レコード数とカラム数（今回は10列×53940行です。）
- **欠損値**：レコード数 - non-null=欠損値数（今回はどのカラムにも欠損値は存在しませんでした）
- **変数の尺度**：カラムのデータ型やdf.head()の内容から把握します。（今回は量的変数が7つ、質的変数が3つあります。）

### 記述統計量の確認

```python
df.describe()
```

ここでは量的変数の記述統計量を確認します。ポイントは以下になります。
- **平均値と中央値の差**：平均に対して中央値が大きく乖離している場合、外れ値によって平均値に影響が出ている可能性があります。
- **値の範囲**：最小値/最大値から、値が分布している範囲を確認します。
- **四分位範囲**：Q1～Q3が狭い範囲で集約しているにもかかわらず、最小値/最大値と極端に差がある場合は、外れ値の可能性があります。

### 量的変数の分布確認

```python
# 数値型の列名を取得
numeric_cols = df.select_dtypes(include='number').columns

# 描画領域を生成
fig, axes = plt.subplots(nrows=len(numeric_cols), ncols=2, figsize=(10, len(numeric_cols) * 2.2))

# 各数値列に対してループ処理
for i, col in enumerate(numeric_cols):
    # ヒストグラムを左側に描画
    sns.histplot(df[col], bins=30, ax=axes[i, 0], kde=False)
    axes[i, 0].set_title(col)

    # 箱ひげ図を右側に描画
    sns.boxplot(x=df[col], ax=axes[i, 1])
    axes[i, 1].set_title(col)

# 余白の自動調整
plt.tight_layout()

# グラフの表示
plt.show()
```

ここでは、以下を確認します。
- **分布の偏り、形状**：正規分布と比較して、ヒストグラムがどのような形状であるか確認します（左右に偏っている、中央が尖っている、山が２つあるなど）。ヒストグラムの形状によって今後のアプローチが変化しますが、詳細は次のステップ「前処理」にて説明します。
- **外れ値**：内境界点より外側にある点を確認します。外れ値は異常値か、機械学習モデルへの学習要否等は次ステップ以降で判断します。
- **目的変数の分布**：priceの分布は左に偏っていることがわかります。このことから、ダイヤモンドの価格は大多数の安価なものと少数の高価なもので構成されていることがわかります。

**用語**
- **正規分布**：データが平均値の付近に集中し、左右対称の釣鐘型をした分布です。統計学では、サンプルデータの分布を評価・比較する際の基準として正規分布が広く使われています。これは、多くの自然現象や測定値などが中心極限定理により正規分布に近づくと考えられているためです。

※中心極限定理：母集団の分布にかかわらず、十分な大きさの標本の平均値は正規分布に近づくとする統計学の基本法則

### 質的変数の構成確認

```python
# カテゴリ変数の列名を定義
categorical_cols = ['cut', 'color', 'clarity']

fig, axes = plt.subplots(1, 3, figsize=(12, 4))

# 各カテゴリ変数にループ処理
for ax, col in zip(axes, categorical_cols):
    # グラフの描画
    sns.countplot(data=df, x=col, ax=ax)  
    ax.tick_params(axis='x', rotation=45) 

plt.tight_layout()
plt.show()
```

ここでは、各カテゴリのデータ数にどのような差があるか把握します。
このグラフからは以下のような情報を読み取ることができます。
- **Cut**：Ideal(最頻値)、Fair(最小頻度値)→カテゴリ数に10倍程度差がある
- **Color**：G(最頻値)、J(最小頻度値)→カテゴリ数に5倍程度差がある
- **Clarity**：SI1(最頻値)、I(最小頻度値)→カテゴリ数に10倍程度差がある

この比較結果が機械学習に影響を与えるかどうかはここでは判断できないため、次ステップ以降で判断します。

### 変数間の関係性の確認

#### 量的変数×量的変数の関係性

```python
import itertools

# 数値型の列名を取得
numeric_cols = df.select_dtypes(include='number').columns

# 数値列のすべてのペアを定義
pairs = list(itertools.combinations(numeric_cols, 2))  

#グラフ描画の行数と列数を指定
ncols = 3  
nrows = (len(pairs) + ncols - 1) // ncols

#散布図の描画領域を生成
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows * 4)) 
axes = axes.flatten()  

# 各ペアに対して散布図を描画
for ax, (x, y) in zip(axes, pairs):
    sns.scatterplot(data=df, x=x, y=y, ax=ax, alpha=0.3)
    ax.set_title(f'{x} vs {y}')

plt.tight_layout()
plt.show()

# 数値型列の相関係数を計算
corr = df[numeric_cols].corr() 

# ヒートマップの描画サイズを指定
plt.figure(figsize=(6, 5))

#相関係数ヒートマップを描画
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)  
plt.title('Correlation Heatmap')
plt.show()
```

ここでは、量的変数同士の相関を確認します。
結果から以下のような情報を得ることができます。
- **目的変数(price)に対して、carat,x,y,zの相関係数が非常に高い**  
  →ダイヤモンドの大きさや重さが価格に影響していることがわかります。
- **x,y,z間も共に相関が高い**  
  →caratはダイヤモンドの重さを示す特徴量であるため、xyz(大きさ)とcarat(重さ)に相関関係があるのは必然的。多重共線性を排除するためにどちらかの特徴量に絞る必要があることがわかります。

#### 質的変数×質的変数の関係性

```python
# クロス集計表を作成
cross1 = pd.crosstab(df['cut'], df['clarity'])   # 'cut'と'clarity'のクロス集計
cross2 = pd.crosstab(df['color'], df['clarity']) # 'color'と'clarity'のクロス集計
cross3 = pd.crosstab(df['cut'], df['color'])     # 'cut'と'color'のクロス集計

# グラフの描画領域を生成
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# クロス集計表を積み上げ棒グラフとして描画
cross1.plot(kind='bar', stacked=True, ax=axes[0])
axes[0].set_title('cut × clarity') 

cross2.plot(kind='bar', stacked=True, ax=axes[1])
axes[1].set_title('color × clarity')

cross3.plot(kind='bar', stacked=True, ax=axes[2])
axes[2].set_title('cut × color')

# 各グラフの凡例の設定
for ax in axes:
    ax.legend(title='category', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()
```

ここでは、質的変数同士を比較した際の構成比の偏りについて比較します。
結果から質的変数間に大きな偏りは確認されませんでした。

#### 量的変数×質的変数の関係性

```python
# カテゴリ変数と数値変数の列名をそれぞれ取得
cat_cols = df.select_dtypes(include='category').columns.tolist()
num_cols = df.select_dtypes(include='number').columns.tolist()

# プロットの行数と列数を設定
nrows = len(num_cols)
ncols = len(cat_cols)

# グラフの描画領域の生成
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5*ncols, 4*nrows), squeeze=False)

# 箱ひげ図の描画
for i, num in enumerate(num_cols):        # 数値変数ごとのループ（行）
    for j, cat in enumerate(cat_cols):    # カテゴリ変数ごとのループ（列）
        ax = axes[i][j]
        sns.boxplot(data=df, x=cat, y=num, ax=ax, showfliers=False)
        ax.set_title(f'{num} by {cat}')
        ax.set_xlabel('')
        ax.set_ylabel(num)
        ax.tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
```

ここでは以下が確認ポイントです。
- **変数間の関係**：カラットと透明度(I1～FL)、色(J～D)の関係性ですが、グレードが高くなるにつれてカラットが小さくなるのは、大きいと悪い部分が目立ちやすいであったり、加工段階において悪い部分を取り除くからだと推測できます。これにより、逆相関の関係になっていると考えられます。
- **目的変数への影響**：colorやclarityのグレードが高くなるにつれ、価格の分布が低くなるのは前述のカラットとの逆相関の関係によるためだと考えられます。このことから、ダイヤモンドの品質よりも大きさや重さが価値の向上に重要な要素であることがわかります。

## まとめ

探索的データ分析（EDA）では確認するべき項目を抑え、データの特徴を把握することが重要です。また把握するだけでなく今後のステップでのアプローチも検討する必要があります。

次回は、EDAで得られた洞察を用いて「前処理」をテーマにデータを機械学習モデルに適した形に加工するプロセスを詳しく解説します。
ぜひ引き続きご覧ください。